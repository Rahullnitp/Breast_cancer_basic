{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breast_cancer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFQE2+HfhM0PlDZtTU99RV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahullnitp/Breast_cancer_basic/blob/master/breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWM-_VmimNlO",
        "colab_type": "code",
        "outputId": "5448a471-97dc-4f06-ff02-d5218b786d0f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2fb7fef1-a5e4-45fe-b14b-fb7731369b04\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2fb7fef1-a5e4-45fe-b14b-fb7731369b04\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving BreastCancer_Prognostic_v1.xlsx to BreastCancer_Prognostic_v1 (2).xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMX18S4rmTwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LCcl5qHmrIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_excel(\"/content/BreastCancer_Prognostic_v1.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l2_vnjSnBgZ",
        "colab_type": "code",
        "outputId": "5e29791b-d61d-4d0b-bada-538f3416b29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Time</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_std_dev</th>\n",
              "      <th>texture_std_dev</th>\n",
              "      <th>perimeter_std_dev</th>\n",
              "      <th>area_std_dev</th>\n",
              "      <th>smoothness_std_dev</th>\n",
              "      <th>compactness_std_dev</th>\n",
              "      <th>concavity_std_dev</th>\n",
              "      <th>concave_points_std_dev</th>\n",
              "      <th>symmetry_std_dev</th>\n",
              "      <th>fractal_dimension_std_dev</th>\n",
              "      <th>Worst_radius</th>\n",
              "      <th>Worst_texture</th>\n",
              "      <th>Worst_perimeter</th>\n",
              "      <th>Worst_area</th>\n",
              "      <th>Worst_smoothness</th>\n",
              "      <th>Worst_compactness</th>\n",
              "      <th>Worst_concavity</th>\n",
              "      <th>Worst_concave_points</th>\n",
              "      <th>Worst_symmetry</th>\n",
              "      <th>Worst_fractal_dimension</th>\n",
              "      <th>Tumor_Size</th>\n",
              "      <th>Lymph_Node_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119513</td>\n",
              "      <td>N</td>\n",
              "      <td>31</td>\n",
              "      <td>18.02</td>\n",
              "      <td>27.60</td>\n",
              "      <td>117.50</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>0.09489</td>\n",
              "      <td>0.1036</td>\n",
              "      <td>0.1086</td>\n",
              "      <td>0.07055</td>\n",
              "      <td>0.1865</td>\n",
              "      <td>0.06333</td>\n",
              "      <td>0.6249</td>\n",
              "      <td>1.8900</td>\n",
              "      <td>3.972</td>\n",
              "      <td>71.55</td>\n",
              "      <td>0.004433</td>\n",
              "      <td>0.01421</td>\n",
              "      <td>0.03233</td>\n",
              "      <td>0.009854</td>\n",
              "      <td>0.01694</td>\n",
              "      <td>0.003495</td>\n",
              "      <td>21.63</td>\n",
              "      <td>37.08</td>\n",
              "      <td>139.70</td>\n",
              "      <td>1436.0</td>\n",
              "      <td>0.1195</td>\n",
              "      <td>0.1926</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.2677</td>\n",
              "      <td>0.08113</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8423</td>\n",
              "      <td>N</td>\n",
              "      <td>61</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.2776</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>842517</td>\n",
              "      <td>N</td>\n",
              "      <td>116</td>\n",
              "      <td>21.37</td>\n",
              "      <td>17.44</td>\n",
              "      <td>137.50</td>\n",
              "      <td>1373.0</td>\n",
              "      <td>0.08836</td>\n",
              "      <td>0.1189</td>\n",
              "      <td>0.1255</td>\n",
              "      <td>0.08180</td>\n",
              "      <td>0.2333</td>\n",
              "      <td>0.06010</td>\n",
              "      <td>0.5854</td>\n",
              "      <td>0.6105</td>\n",
              "      <td>3.928</td>\n",
              "      <td>82.15</td>\n",
              "      <td>0.006167</td>\n",
              "      <td>0.03449</td>\n",
              "      <td>0.03300</td>\n",
              "      <td>0.018050</td>\n",
              "      <td>0.03094</td>\n",
              "      <td>0.005039</td>\n",
              "      <td>24.90</td>\n",
              "      <td>20.98</td>\n",
              "      <td>159.10</td>\n",
              "      <td>1949.0</td>\n",
              "      <td>0.1188</td>\n",
              "      <td>0.3449</td>\n",
              "      <td>0.3414</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4334</td>\n",
              "      <td>0.09067</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>843483</td>\n",
              "      <td>N</td>\n",
              "      <td>123</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>843584</td>\n",
              "      <td>R</td>\n",
              "      <td>27</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.1328</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID Outcome  Time  ...  Worst_fractal_dimension  Tumor_Size  Lymph_Node_Status\n",
              "0  119513       N    31  ...                  0.08113         5.0                  5\n",
              "1    8423       N    61  ...                  0.11890         3.0                  2\n",
              "2  842517       N   116  ...                  0.09067         2.5                  0\n",
              "3  843483       N   123  ...                  0.17300         2.0                  0\n",
              "4  843584       R    27  ...                  0.07678         3.5                  0\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYZBmBrQnDLa",
        "colab_type": "code",
        "outputId": "df2f91b8-3c52-4212-cfa3-24536f90390f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 198 entries, 0 to 197\n",
            "Data columns (total 35 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   ID                         198 non-null    int64  \n",
            " 1   Outcome                    198 non-null    object \n",
            " 2   Time                       198 non-null    int64  \n",
            " 3   radius_mean                198 non-null    float64\n",
            " 4   texture_mean               198 non-null    float64\n",
            " 5   perimeter_mean             198 non-null    float64\n",
            " 6   area_mean                  198 non-null    float64\n",
            " 7   smoothness_mean            198 non-null    float64\n",
            " 8   compactness_mean           198 non-null    float64\n",
            " 9   concavity_mean             198 non-null    float64\n",
            " 10  concave_points_mean        198 non-null    float64\n",
            " 11  symmetry_mean              198 non-null    float64\n",
            " 12  fractal_dimension_mean     198 non-null    float64\n",
            " 13  radius_std_dev             198 non-null    float64\n",
            " 14  texture_std_dev            198 non-null    float64\n",
            " 15  perimeter_std_dev          198 non-null    float64\n",
            " 16  area_std_dev               198 non-null    float64\n",
            " 17  smoothness_std_dev         198 non-null    float64\n",
            " 18  compactness_std_dev        198 non-null    float64\n",
            " 19  concavity_std_dev          198 non-null    float64\n",
            " 20  concave_points_std_dev     198 non-null    float64\n",
            " 21  symmetry_std_dev           198 non-null    float64\n",
            " 22  fractal_dimension_std_dev  198 non-null    float64\n",
            " 23  Worst_radius               198 non-null    float64\n",
            " 24  Worst_texture              198 non-null    float64\n",
            " 25  Worst_perimeter            198 non-null    float64\n",
            " 26  Worst_area                 198 non-null    float64\n",
            " 27  Worst_smoothness           198 non-null    float64\n",
            " 28  Worst_compactness          198 non-null    float64\n",
            " 29  Worst_concavity            198 non-null    float64\n",
            " 30  Worst_concave_points       198 non-null    float64\n",
            " 31  Worst_symmetry             198 non-null    float64\n",
            " 32  Worst_fractal_dimension    198 non-null    float64\n",
            " 33  Tumor_Size                 198 non-null    float64\n",
            " 34  Lymph_Node_Status          198 non-null    object \n",
            "dtypes: float64(31), int64(2), object(2)\n",
            "memory usage: 54.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADYggVFQpQDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data[data.Lymph_Node_Status.apply(lambda x: x.isnumeric())]\n",
        "data=data[data['Lymph_Node_Status'].apply(lambda x: isinstance(x, (int, np.int64)))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eknamw3ZnH-S",
        "colab_type": "code",
        "outputId": "02d755e1-5a9a-4d7e-afdc-fac1fdea49e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "data.drop(['ID'], axis=1, inplace=True)\n",
        "# data.drop(['Lymph_Node_Status'], axis=1, inplace=True)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Time</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_std_dev</th>\n",
              "      <th>texture_std_dev</th>\n",
              "      <th>perimeter_std_dev</th>\n",
              "      <th>area_std_dev</th>\n",
              "      <th>smoothness_std_dev</th>\n",
              "      <th>compactness_std_dev</th>\n",
              "      <th>concavity_std_dev</th>\n",
              "      <th>concave_points_std_dev</th>\n",
              "      <th>symmetry_std_dev</th>\n",
              "      <th>fractal_dimension_std_dev</th>\n",
              "      <th>Worst_radius</th>\n",
              "      <th>Worst_texture</th>\n",
              "      <th>Worst_perimeter</th>\n",
              "      <th>Worst_area</th>\n",
              "      <th>Worst_smoothness</th>\n",
              "      <th>Worst_compactness</th>\n",
              "      <th>Worst_concavity</th>\n",
              "      <th>Worst_concave_points</th>\n",
              "      <th>Worst_symmetry</th>\n",
              "      <th>Worst_fractal_dimension</th>\n",
              "      <th>Tumor_Size</th>\n",
              "      <th>Lymph_Node_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N</td>\n",
              "      <td>31</td>\n",
              "      <td>18.02</td>\n",
              "      <td>27.60</td>\n",
              "      <td>117.50</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>0.09489</td>\n",
              "      <td>0.1036</td>\n",
              "      <td>0.1086</td>\n",
              "      <td>0.07055</td>\n",
              "      <td>0.1865</td>\n",
              "      <td>0.06333</td>\n",
              "      <td>0.6249</td>\n",
              "      <td>1.8900</td>\n",
              "      <td>3.972</td>\n",
              "      <td>71.55</td>\n",
              "      <td>0.004433</td>\n",
              "      <td>0.01421</td>\n",
              "      <td>0.03233</td>\n",
              "      <td>0.009854</td>\n",
              "      <td>0.01694</td>\n",
              "      <td>0.003495</td>\n",
              "      <td>21.63</td>\n",
              "      <td>37.08</td>\n",
              "      <td>139.70</td>\n",
              "      <td>1436.0</td>\n",
              "      <td>0.1195</td>\n",
              "      <td>0.1926</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.2677</td>\n",
              "      <td>0.08113</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N</td>\n",
              "      <td>61</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.2776</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N</td>\n",
              "      <td>116</td>\n",
              "      <td>21.37</td>\n",
              "      <td>17.44</td>\n",
              "      <td>137.50</td>\n",
              "      <td>1373.0</td>\n",
              "      <td>0.08836</td>\n",
              "      <td>0.1189</td>\n",
              "      <td>0.1255</td>\n",
              "      <td>0.08180</td>\n",
              "      <td>0.2333</td>\n",
              "      <td>0.06010</td>\n",
              "      <td>0.5854</td>\n",
              "      <td>0.6105</td>\n",
              "      <td>3.928</td>\n",
              "      <td>82.15</td>\n",
              "      <td>0.006167</td>\n",
              "      <td>0.03449</td>\n",
              "      <td>0.03300</td>\n",
              "      <td>0.018050</td>\n",
              "      <td>0.03094</td>\n",
              "      <td>0.005039</td>\n",
              "      <td>24.90</td>\n",
              "      <td>20.98</td>\n",
              "      <td>159.10</td>\n",
              "      <td>1949.0</td>\n",
              "      <td>0.1188</td>\n",
              "      <td>0.3449</td>\n",
              "      <td>0.3414</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4334</td>\n",
              "      <td>0.09067</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N</td>\n",
              "      <td>123</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>R</td>\n",
              "      <td>27</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.1328</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Outcome  Time  ...  Tumor_Size  Lymph_Node_Status\n",
              "0       N    31  ...         5.0                  5\n",
              "1       N    61  ...         3.0                  2\n",
              "2       N   116  ...         2.5                  0\n",
              "3       N   123  ...         2.0                  0\n",
              "4       R    27  ...         3.5                  0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqe6IqbNnk_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = data.iloc[:, 1:].values\n",
        "label = data.iloc[:, 0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuF0-Kodn05Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqaz-iE6oI5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApUvZQC6oeoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "fit=StandardScaler()\n",
        "X_train =fit.fit_transform(X_train)\n",
        "X_test = fit.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBJYl9eqoo-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmiEic0NsHkB",
        "colab_type": "code",
        "outputId": "089d448b-ca48-41d9-8190-fa4ecba9fec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "model=SVC()\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMVzJ2n_sfNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUqAO0S8s5JA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSCLhNOItXJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid={'C':[0.01,0.1,1,10,100],'gamma':[1,0.1,0.01,0.001,0.0001],'kernel':['rbf']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9SljKy_tXj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb5r9LaTtZFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid=GridSearchCV(SVC(),param_grid,refit=True,verbose=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJTFSgFutaeu",
        "colab_type": "code",
        "outputId": "b89a5beb-9620-4d6c-85d9-c150764fdadd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=0.01, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=0.01, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=0.01, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=0.01, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.01, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=0.01, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=0.01, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=0.01, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=0.01, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=0.01, gamma=0.1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=0.01, gamma=0.1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=0.01, gamma=0.01, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=0.01, gamma=0.01, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=0.01, gamma=0.01, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=0.01, gamma=0.01, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=0.01, gamma=0.01, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=0.01, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=0.01, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=0.01, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=0.01, gamma=0.001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=0.01, gamma=0.001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=0.01, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=0.01, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=0.01, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=0.01, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.01, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=0.01, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.806, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.806, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.839, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.710, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.806, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.839, total=   0.0s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.839, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.806, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.839, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.645, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.806, total=   0.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.839, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.839, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.839, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.839, total=   0.0s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.806, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.774, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.742, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['rbf']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lASYHpotsmd",
        "colab_type": "code",
        "outputId": "bd6199fc-baa7-4cc7-9eb3-f21ae24ccbc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAeW8l1hurVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_predictions=grid.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_nB3t_AuzZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res1=confusion_matrix(y_test,grid_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xbl1i4eu1TS",
        "colab_type": "code",
        "outputId": "35e586e2-c4c5-4cf4-b3f2-1aec12f18999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "sns.heatmap(res1,annot=True)\n",
        "plt.ioff()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M82kBzJu6UL",
        "colab_type": "code",
        "outputId": "48748ff6-9a18-424a-deec-db49d9e63287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print(classification_report(y_test,grid_predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      1.00      0.88        30\n",
            "           1       1.00      0.11      0.20         9\n",
            "\n",
            "    accuracy                           0.79        39\n",
            "   macro avg       0.89      0.56      0.54        39\n",
            "weighted avg       0.84      0.79      0.72        39\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Sd-rUbvA0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhPDUf-zdoeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYgQ-5GEdoaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4scVcYigHOT",
        "colab_type": "text"
      },
      "source": [
        "##Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD1jPLTEdoXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvl0edF9bjbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDXw9vgObjYn",
        "colab_type": "code",
        "outputId": "6f91d6b1-9148-4f40-da3a-060b8cec2d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=33))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('softmax'))\n",
        "model.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szSB8khqgQvI",
        "colab_type": "code",
        "outputId": "70cbb5dd-e6f7-4955-d9d1-b7851929834e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train,y_train, epochs=200, batch_size=16, validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 155 samples, validate on 39 samples\n",
            "Epoch 1/200\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.6895 - accuracy: 0.7548 - val_loss: 0.6863 - val_accuracy: 0.7692\n",
            "Epoch 2/200\n",
            "155/155 [==============================] - 0s 508us/step - loss: 0.6840 - accuracy: 0.7613 - val_loss: 0.6822 - val_accuracy: 0.7692\n",
            "Epoch 3/200\n",
            "155/155 [==============================] - 0s 420us/step - loss: 0.6789 - accuracy: 0.7613 - val_loss: 0.6779 - val_accuracy: 0.7692\n",
            "Epoch 4/200\n",
            "155/155 [==============================] - 0s 506us/step - loss: 0.6734 - accuracy: 0.7613 - val_loss: 0.6739 - val_accuracy: 0.7692\n",
            "Epoch 5/200\n",
            "155/155 [==============================] - 0s 432us/step - loss: 0.6679 - accuracy: 0.7613 - val_loss: 0.6698 - val_accuracy: 0.7692\n",
            "Epoch 6/200\n",
            "155/155 [==============================] - 0s 424us/step - loss: 0.6612 - accuracy: 0.7613 - val_loss: 0.6659 - val_accuracy: 0.7692\n",
            "Epoch 7/200\n",
            "155/155 [==============================] - 0s 500us/step - loss: 0.6551 - accuracy: 0.7613 - val_loss: 0.6621 - val_accuracy: 0.7692\n",
            "Epoch 8/200\n",
            "155/155 [==============================] - 0s 498us/step - loss: 0.6484 - accuracy: 0.7613 - val_loss: 0.6581 - val_accuracy: 0.7692\n",
            "Epoch 9/200\n",
            "155/155 [==============================] - 0s 417us/step - loss: 0.6424 - accuracy: 0.7613 - val_loss: 0.6536 - val_accuracy: 0.7692\n",
            "Epoch 10/200\n",
            "155/155 [==============================] - 0s 410us/step - loss: 0.6341 - accuracy: 0.7613 - val_loss: 0.6470 - val_accuracy: 0.7692\n",
            "Epoch 11/200\n",
            "155/155 [==============================] - 0s 419us/step - loss: 0.6264 - accuracy: 0.7613 - val_loss: 0.6393 - val_accuracy: 0.7692\n",
            "Epoch 12/200\n",
            "155/155 [==============================] - 0s 459us/step - loss: 0.6185 - accuracy: 0.7613 - val_loss: 0.6327 - val_accuracy: 0.7692\n",
            "Epoch 13/200\n",
            "155/155 [==============================] - 0s 415us/step - loss: 0.6134 - accuracy: 0.7613 - val_loss: 0.6250 - val_accuracy: 0.7692\n",
            "Epoch 14/200\n",
            "155/155 [==============================] - 0s 408us/step - loss: 0.6093 - accuracy: 0.7613 - val_loss: 0.6174 - val_accuracy: 0.7692\n",
            "Epoch 15/200\n",
            "155/155 [==============================] - 0s 441us/step - loss: 0.5999 - accuracy: 0.7613 - val_loss: 0.6138 - val_accuracy: 0.7692\n",
            "Epoch 16/200\n",
            "155/155 [==============================] - 0s 530us/step - loss: 0.5917 - accuracy: 0.7613 - val_loss: 0.6084 - val_accuracy: 0.7692\n",
            "Epoch 17/200\n",
            "155/155 [==============================] - 0s 406us/step - loss: 0.5868 - accuracy: 0.7613 - val_loss: 0.6040 - val_accuracy: 0.7692\n",
            "Epoch 18/200\n",
            "155/155 [==============================] - 0s 417us/step - loss: 0.5821 - accuracy: 0.7806 - val_loss: 0.6012 - val_accuracy: 0.7692\n",
            "Epoch 19/200\n",
            "155/155 [==============================] - 0s 413us/step - loss: 0.5772 - accuracy: 0.8194 - val_loss: 0.6006 - val_accuracy: 0.7692\n",
            "Epoch 20/200\n",
            "155/155 [==============================] - 0s 428us/step - loss: 0.5801 - accuracy: 0.8129 - val_loss: 0.5989 - val_accuracy: 0.7692\n",
            "Epoch 21/200\n",
            "155/155 [==============================] - 0s 407us/step - loss: 0.5682 - accuracy: 0.8387 - val_loss: 0.5931 - val_accuracy: 0.7692\n",
            "Epoch 22/200\n",
            "155/155 [==============================] - 0s 416us/step - loss: 0.5583 - accuracy: 0.8452 - val_loss: 0.5854 - val_accuracy: 0.7692\n",
            "Epoch 23/200\n",
            "155/155 [==============================] - 0s 490us/step - loss: 0.5564 - accuracy: 0.8581 - val_loss: 0.5840 - val_accuracy: 0.7949\n",
            "Epoch 24/200\n",
            "155/155 [==============================] - 0s 418us/step - loss: 0.5548 - accuracy: 0.8645 - val_loss: 0.5803 - val_accuracy: 0.7692\n",
            "Epoch 25/200\n",
            "155/155 [==============================] - 0s 429us/step - loss: 0.5558 - accuracy: 0.8194 - val_loss: 0.5814 - val_accuracy: 0.7692\n",
            "Epoch 26/200\n",
            "155/155 [==============================] - 0s 418us/step - loss: 0.5499 - accuracy: 0.8387 - val_loss: 0.5825 - val_accuracy: 0.7949\n",
            "Epoch 27/200\n",
            "155/155 [==============================] - 0s 430us/step - loss: 0.5409 - accuracy: 0.8710 - val_loss: 0.5832 - val_accuracy: 0.7692\n",
            "Epoch 28/200\n",
            "155/155 [==============================] - 0s 409us/step - loss: 0.5357 - accuracy: 0.8774 - val_loss: 0.5760 - val_accuracy: 0.7949\n",
            "Epoch 29/200\n",
            "155/155 [==============================] - 0s 412us/step - loss: 0.5267 - accuracy: 0.8839 - val_loss: 0.5715 - val_accuracy: 0.7692\n",
            "Epoch 30/200\n",
            "155/155 [==============================] - 0s 402us/step - loss: 0.5340 - accuracy: 0.8645 - val_loss: 0.5708 - val_accuracy: 0.7692\n",
            "Epoch 31/200\n",
            "155/155 [==============================] - 0s 552us/step - loss: 0.5196 - accuracy: 0.8839 - val_loss: 0.5615 - val_accuracy: 0.7692\n",
            "Epoch 32/200\n",
            "155/155 [==============================] - 0s 409us/step - loss: 0.5213 - accuracy: 0.8516 - val_loss: 0.5604 - val_accuracy: 0.7692\n",
            "Epoch 33/200\n",
            "155/155 [==============================] - 0s 396us/step - loss: 0.5051 - accuracy: 0.8903 - val_loss: 0.5757 - val_accuracy: 0.7436\n",
            "Epoch 34/200\n",
            "155/155 [==============================] - 0s 408us/step - loss: 0.5234 - accuracy: 0.8323 - val_loss: 0.5626 - val_accuracy: 0.7949\n",
            "Epoch 35/200\n",
            "155/155 [==============================] - 0s 525us/step - loss: 0.5043 - accuracy: 0.8968 - val_loss: 0.5709 - val_accuracy: 0.7436\n",
            "Epoch 36/200\n",
            "155/155 [==============================] - 0s 548us/step - loss: 0.5181 - accuracy: 0.8452 - val_loss: 0.5733 - val_accuracy: 0.7179\n",
            "Epoch 37/200\n",
            "155/155 [==============================] - 0s 471us/step - loss: 0.5022 - accuracy: 0.8774 - val_loss: 0.5697 - val_accuracy: 0.7692\n",
            "Epoch 38/200\n",
            "155/155 [==============================] - 0s 421us/step - loss: 0.5060 - accuracy: 0.8581 - val_loss: 0.5681 - val_accuracy: 0.7436\n",
            "Epoch 39/200\n",
            "155/155 [==============================] - 0s 405us/step - loss: 0.4990 - accuracy: 0.8581 - val_loss: 0.5653 - val_accuracy: 0.7179\n",
            "Epoch 40/200\n",
            "155/155 [==============================] - 0s 431us/step - loss: 0.4922 - accuracy: 0.8839 - val_loss: 0.5471 - val_accuracy: 0.7949\n",
            "Epoch 41/200\n",
            "155/155 [==============================] - 0s 443us/step - loss: 0.4815 - accuracy: 0.9032 - val_loss: 0.5419 - val_accuracy: 0.7949\n",
            "Epoch 42/200\n",
            "155/155 [==============================] - 0s 424us/step - loss: 0.4894 - accuracy: 0.8839 - val_loss: 0.5458 - val_accuracy: 0.7692\n",
            "Epoch 43/200\n",
            "155/155 [==============================] - 0s 422us/step - loss: 0.4685 - accuracy: 0.8968 - val_loss: 0.5515 - val_accuracy: 0.7436\n",
            "Epoch 44/200\n",
            "155/155 [==============================] - 0s 429us/step - loss: 0.4786 - accuracy: 0.8645 - val_loss: 0.5587 - val_accuracy: 0.7692\n",
            "Epoch 45/200\n",
            "155/155 [==============================] - 0s 546us/step - loss: 0.4572 - accuracy: 0.9355 - val_loss: 0.5494 - val_accuracy: 0.7949\n",
            "Epoch 46/200\n",
            "155/155 [==============================] - 0s 401us/step - loss: 0.4569 - accuracy: 0.9226 - val_loss: 0.5461 - val_accuracy: 0.7949\n",
            "Epoch 47/200\n",
            "155/155 [==============================] - 0s 410us/step - loss: 0.4692 - accuracy: 0.8774 - val_loss: 0.5443 - val_accuracy: 0.7949\n",
            "Epoch 48/200\n",
            "155/155 [==============================] - 0s 427us/step - loss: 0.4621 - accuracy: 0.9226 - val_loss: 0.5528 - val_accuracy: 0.7692\n",
            "Epoch 49/200\n",
            "155/155 [==============================] - 0s 435us/step - loss: 0.4626 - accuracy: 0.8968 - val_loss: 0.5568 - val_accuracy: 0.7436\n",
            "Epoch 50/200\n",
            "155/155 [==============================] - 0s 409us/step - loss: 0.4537 - accuracy: 0.9097 - val_loss: 0.5590 - val_accuracy: 0.7436\n",
            "Epoch 51/200\n",
            "155/155 [==============================] - 0s 440us/step - loss: 0.4471 - accuracy: 0.9226 - val_loss: 0.5408 - val_accuracy: 0.7692\n",
            "Epoch 52/200\n",
            "155/155 [==============================] - 0s 403us/step - loss: 0.4617 - accuracy: 0.8774 - val_loss: 0.5326 - val_accuracy: 0.7949\n",
            "Epoch 53/200\n",
            "155/155 [==============================] - 0s 434us/step - loss: 0.4654 - accuracy: 0.8516 - val_loss: 0.5281 - val_accuracy: 0.7949\n",
            "Epoch 54/200\n",
            "155/155 [==============================] - 0s 473us/step - loss: 0.4470 - accuracy: 0.8903 - val_loss: 0.5646 - val_accuracy: 0.7179\n",
            "Epoch 55/200\n",
            "155/155 [==============================] - 0s 428us/step - loss: 0.4378 - accuracy: 0.9161 - val_loss: 0.5658 - val_accuracy: 0.7179\n",
            "Epoch 56/200\n",
            "155/155 [==============================] - 0s 426us/step - loss: 0.4412 - accuracy: 0.8968 - val_loss: 0.5526 - val_accuracy: 0.7436\n",
            "Epoch 57/200\n",
            "155/155 [==============================] - 0s 510us/step - loss: 0.4433 - accuracy: 0.9032 - val_loss: 0.5152 - val_accuracy: 0.8205\n",
            "Epoch 58/200\n",
            "155/155 [==============================] - 0s 434us/step - loss: 0.4535 - accuracy: 0.8581 - val_loss: 0.4999 - val_accuracy: 0.8462\n",
            "Epoch 59/200\n",
            "155/155 [==============================] - 0s 438us/step - loss: 0.4408 - accuracy: 0.9032 - val_loss: 0.4992 - val_accuracy: 0.8205\n",
            "Epoch 60/200\n",
            "155/155 [==============================] - 0s 562us/step - loss: 0.4326 - accuracy: 0.9032 - val_loss: 0.5093 - val_accuracy: 0.7949\n",
            "Epoch 61/200\n",
            "155/155 [==============================] - 0s 415us/step - loss: 0.4294 - accuracy: 0.9032 - val_loss: 0.5234 - val_accuracy: 0.7949\n",
            "Epoch 62/200\n",
            "155/155 [==============================] - 0s 422us/step - loss: 0.4147 - accuracy: 0.9290 - val_loss: 0.5216 - val_accuracy: 0.7949\n",
            "Epoch 63/200\n",
            "155/155 [==============================] - 0s 416us/step - loss: 0.4112 - accuracy: 0.9290 - val_loss: 0.5335 - val_accuracy: 0.7436\n",
            "Epoch 64/200\n",
            "155/155 [==============================] - 0s 409us/step - loss: 0.4298 - accuracy: 0.8903 - val_loss: 0.5171 - val_accuracy: 0.7949\n",
            "Epoch 65/200\n",
            "155/155 [==============================] - 0s 473us/step - loss: 0.4231 - accuracy: 0.9161 - val_loss: 0.5136 - val_accuracy: 0.7949\n",
            "Epoch 66/200\n",
            "155/155 [==============================] - 0s 405us/step - loss: 0.4166 - accuracy: 0.9161 - val_loss: 0.5031 - val_accuracy: 0.7949\n",
            "Epoch 67/200\n",
            "155/155 [==============================] - 0s 407us/step - loss: 0.4165 - accuracy: 0.9032 - val_loss: 0.4964 - val_accuracy: 0.8205\n",
            "Epoch 68/200\n",
            "155/155 [==============================] - 0s 501us/step - loss: 0.4374 - accuracy: 0.8774 - val_loss: 0.5054 - val_accuracy: 0.7949\n",
            "Epoch 69/200\n",
            "155/155 [==============================] - 0s 440us/step - loss: 0.4006 - accuracy: 0.9161 - val_loss: 0.5357 - val_accuracy: 0.7692\n",
            "Epoch 70/200\n",
            "155/155 [==============================] - 0s 404us/step - loss: 0.3942 - accuracy: 0.9290 - val_loss: 0.5301 - val_accuracy: 0.7692\n",
            "Epoch 71/200\n",
            "155/155 [==============================] - 0s 425us/step - loss: 0.3885 - accuracy: 0.9290 - val_loss: 0.5288 - val_accuracy: 0.7949\n",
            "Epoch 72/200\n",
            "155/155 [==============================] - 0s 416us/step - loss: 0.4073 - accuracy: 0.9097 - val_loss: 0.5263 - val_accuracy: 0.7692\n",
            "Epoch 73/200\n",
            "155/155 [==============================] - 0s 497us/step - loss: 0.3784 - accuracy: 0.9419 - val_loss: 0.5036 - val_accuracy: 0.7949\n",
            "Epoch 74/200\n",
            "155/155 [==============================] - 0s 626us/step - loss: 0.3966 - accuracy: 0.9161 - val_loss: 0.5082 - val_accuracy: 0.7692\n",
            "Epoch 75/200\n",
            "155/155 [==============================] - 0s 424us/step - loss: 0.4121 - accuracy: 0.8839 - val_loss: 0.5128 - val_accuracy: 0.7949\n",
            "Epoch 76/200\n",
            "155/155 [==============================] - 0s 432us/step - loss: 0.3985 - accuracy: 0.9226 - val_loss: 0.5203 - val_accuracy: 0.7692\n",
            "Epoch 77/200\n",
            "155/155 [==============================] - 0s 414us/step - loss: 0.3857 - accuracy: 0.9290 - val_loss: 0.5185 - val_accuracy: 0.7692\n",
            "Epoch 78/200\n",
            "155/155 [==============================] - 0s 408us/step - loss: 0.3901 - accuracy: 0.9097 - val_loss: 0.5106 - val_accuracy: 0.7949\n",
            "Epoch 79/200\n",
            "155/155 [==============================] - 0s 471us/step - loss: 0.3803 - accuracy: 0.9226 - val_loss: 0.5142 - val_accuracy: 0.7692\n",
            "Epoch 80/200\n",
            "155/155 [==============================] - 0s 407us/step - loss: 0.3709 - accuracy: 0.9355 - val_loss: 0.5417 - val_accuracy: 0.7692\n",
            "Epoch 81/200\n",
            "155/155 [==============================] - 0s 437us/step - loss: 0.4024 - accuracy: 0.9097 - val_loss: 0.5340 - val_accuracy: 0.7692\n",
            "Epoch 82/200\n",
            "155/155 [==============================] - 0s 412us/step - loss: 0.3730 - accuracy: 0.9097 - val_loss: 0.5311 - val_accuracy: 0.7692\n",
            "Epoch 83/200\n",
            "155/155 [==============================] - 0s 420us/step - loss: 0.3965 - accuracy: 0.8903 - val_loss: 0.5027 - val_accuracy: 0.7692\n",
            "Epoch 84/200\n",
            "155/155 [==============================] - 0s 419us/step - loss: 0.3914 - accuracy: 0.8968 - val_loss: 0.5003 - val_accuracy: 0.7692\n",
            "Epoch 85/200\n",
            "155/155 [==============================] - 0s 415us/step - loss: 0.4004 - accuracy: 0.8774 - val_loss: 0.5082 - val_accuracy: 0.7436\n",
            "Epoch 86/200\n",
            "155/155 [==============================] - 0s 417us/step - loss: 0.3578 - accuracy: 0.9419 - val_loss: 0.5210 - val_accuracy: 0.7179\n",
            "Epoch 87/200\n",
            "155/155 [==============================] - 0s 402us/step - loss: 0.3572 - accuracy: 0.9355 - val_loss: 0.5398 - val_accuracy: 0.7692\n",
            "Epoch 88/200\n",
            "155/155 [==============================] - 0s 403us/step - loss: 0.3883 - accuracy: 0.9032 - val_loss: 0.5395 - val_accuracy: 0.7692\n",
            "Epoch 89/200\n",
            "155/155 [==============================] - 0s 541us/step - loss: 0.3555 - accuracy: 0.9290 - val_loss: 0.5158 - val_accuracy: 0.7436\n",
            "Epoch 90/200\n",
            "155/155 [==============================] - 0s 430us/step - loss: 0.3528 - accuracy: 0.9419 - val_loss: 0.5338 - val_accuracy: 0.7179\n",
            "Epoch 91/200\n",
            "155/155 [==============================] - 0s 409us/step - loss: 0.3463 - accuracy: 0.9484 - val_loss: 0.5180 - val_accuracy: 0.7949\n",
            "Epoch 92/200\n",
            "155/155 [==============================] - 0s 413us/step - loss: 0.3501 - accuracy: 0.9290 - val_loss: 0.5281 - val_accuracy: 0.7949\n",
            "Epoch 93/200\n",
            "155/155 [==============================] - 0s 470us/step - loss: 0.3671 - accuracy: 0.9161 - val_loss: 0.5205 - val_accuracy: 0.7949\n",
            "Epoch 94/200\n",
            "155/155 [==============================] - 0s 515us/step - loss: 0.3675 - accuracy: 0.9032 - val_loss: 0.5333 - val_accuracy: 0.7692\n",
            "Epoch 95/200\n",
            "155/155 [==============================] - 0s 476us/step - loss: 0.3569 - accuracy: 0.9290 - val_loss: 0.5212 - val_accuracy: 0.7949\n",
            "Epoch 96/200\n",
            "155/155 [==============================] - 0s 409us/step - loss: 0.3924 - accuracy: 0.8774 - val_loss: 0.5263 - val_accuracy: 0.7949\n",
            "Epoch 97/200\n",
            "155/155 [==============================] - 0s 418us/step - loss: 0.3498 - accuracy: 0.9290 - val_loss: 0.5311 - val_accuracy: 0.7692\n",
            "Epoch 98/200\n",
            "155/155 [==============================] - 0s 426us/step - loss: 0.3486 - accuracy: 0.9419 - val_loss: 0.5270 - val_accuracy: 0.7949\n",
            "Epoch 99/200\n",
            "155/155 [==============================] - 0s 444us/step - loss: 0.3221 - accuracy: 0.9548 - val_loss: 0.5148 - val_accuracy: 0.7949\n",
            "Epoch 100/200\n",
            "155/155 [==============================] - 0s 407us/step - loss: 0.3181 - accuracy: 0.9548 - val_loss: 0.4991 - val_accuracy: 0.7949\n",
            "Epoch 101/200\n",
            "155/155 [==============================] - 0s 439us/step - loss: 0.3305 - accuracy: 0.9290 - val_loss: 0.5239 - val_accuracy: 0.7692\n",
            "Epoch 102/200\n",
            "155/155 [==============================] - 0s 555us/step - loss: 0.3220 - accuracy: 0.9548 - val_loss: 0.5236 - val_accuracy: 0.7692\n",
            "Epoch 103/200\n",
            "155/155 [==============================] - 0s 511us/step - loss: 0.3563 - accuracy: 0.9097 - val_loss: 0.5394 - val_accuracy: 0.7692\n",
            "Epoch 104/200\n",
            "155/155 [==============================] - 0s 435us/step - loss: 0.3349 - accuracy: 0.9290 - val_loss: 0.5222 - val_accuracy: 0.7949\n",
            "Epoch 105/200\n",
            "155/155 [==============================] - 0s 417us/step - loss: 0.3374 - accuracy: 0.9355 - val_loss: 0.5273 - val_accuracy: 0.7436\n",
            "Epoch 106/200\n",
            "155/155 [==============================] - 0s 539us/step - loss: 0.3211 - accuracy: 0.9419 - val_loss: 0.5289 - val_accuracy: 0.7436\n",
            "Epoch 107/200\n",
            "155/155 [==============================] - 0s 448us/step - loss: 0.3232 - accuracy: 0.9355 - val_loss: 0.5447 - val_accuracy: 0.7179\n",
            "Epoch 108/200\n",
            "155/155 [==============================] - 0s 411us/step - loss: 0.3328 - accuracy: 0.9226 - val_loss: 0.5494 - val_accuracy: 0.7436\n",
            "Epoch 109/200\n",
            "155/155 [==============================] - 0s 434us/step - loss: 0.3074 - accuracy: 0.9419 - val_loss: 0.5344 - val_accuracy: 0.7692\n",
            "Epoch 110/200\n",
            "155/155 [==============================] - 0s 404us/step - loss: 0.3329 - accuracy: 0.9161 - val_loss: 0.5017 - val_accuracy: 0.7949\n",
            "Epoch 111/200\n",
            "155/155 [==============================] - 0s 434us/step - loss: 0.3341 - accuracy: 0.9226 - val_loss: 0.5169 - val_accuracy: 0.7436\n",
            "Epoch 112/200\n",
            "155/155 [==============================] - 0s 449us/step - loss: 0.3030 - accuracy: 0.9548 - val_loss: 0.5225 - val_accuracy: 0.7436\n",
            "Epoch 113/200\n",
            "155/155 [==============================] - 0s 407us/step - loss: 0.3322 - accuracy: 0.9226 - val_loss: 0.5352 - val_accuracy: 0.7179\n",
            "Epoch 114/200\n",
            "155/155 [==============================] - 0s 406us/step - loss: 0.3067 - accuracy: 0.9548 - val_loss: 0.5117 - val_accuracy: 0.7949\n",
            "Epoch 115/200\n",
            "155/155 [==============================] - 0s 400us/step - loss: 0.3029 - accuracy: 0.9548 - val_loss: 0.5109 - val_accuracy: 0.7692\n",
            "Epoch 116/200\n",
            "155/155 [==============================] - 0s 418us/step - loss: 0.3002 - accuracy: 0.9419 - val_loss: 0.4897 - val_accuracy: 0.7949\n",
            "Epoch 117/200\n",
            "155/155 [==============================] - 0s 428us/step - loss: 0.3348 - accuracy: 0.9032 - val_loss: 0.5223 - val_accuracy: 0.7692\n",
            "Epoch 118/200\n",
            "155/155 [==============================] - 0s 542us/step - loss: 0.3258 - accuracy: 0.9226 - val_loss: 0.5083 - val_accuracy: 0.7692\n",
            "Epoch 119/200\n",
            "155/155 [==============================] - 0s 415us/step - loss: 0.3292 - accuracy: 0.9161 - val_loss: 0.5510 - val_accuracy: 0.7436\n",
            "Epoch 120/200\n",
            "155/155 [==============================] - 0s 412us/step - loss: 0.3011 - accuracy: 0.9290 - val_loss: 0.5271 - val_accuracy: 0.7692\n",
            "Epoch 121/200\n",
            "155/155 [==============================] - 0s 421us/step - loss: 0.2982 - accuracy: 0.9548 - val_loss: 0.5247 - val_accuracy: 0.7436\n",
            "Epoch 122/200\n",
            "155/155 [==============================] - 0s 478us/step - loss: 0.3190 - accuracy: 0.9226 - val_loss: 0.5296 - val_accuracy: 0.7436\n",
            "Epoch 123/200\n",
            "155/155 [==============================] - 0s 401us/step - loss: 0.3127 - accuracy: 0.9226 - val_loss: 0.5260 - val_accuracy: 0.7692\n",
            "Epoch 124/200\n",
            "155/155 [==============================] - 0s 421us/step - loss: 0.2901 - accuracy: 0.9613 - val_loss: 0.5396 - val_accuracy: 0.7692\n",
            "Epoch 125/200\n",
            "155/155 [==============================] - 0s 410us/step - loss: 0.3081 - accuracy: 0.9419 - val_loss: 0.5345 - val_accuracy: 0.7692\n",
            "Epoch 126/200\n",
            "155/155 [==============================] - 0s 420us/step - loss: 0.3087 - accuracy: 0.9290 - val_loss: 0.5331 - val_accuracy: 0.7692\n",
            "Epoch 127/200\n",
            "155/155 [==============================] - 0s 421us/step - loss: 0.3168 - accuracy: 0.9290 - val_loss: 0.5225 - val_accuracy: 0.7692\n",
            "Epoch 128/200\n",
            "155/155 [==============================] - 0s 411us/step - loss: 0.3144 - accuracy: 0.9355 - val_loss: 0.5269 - val_accuracy: 0.7692\n",
            "Epoch 129/200\n",
            "155/155 [==============================] - 0s 435us/step - loss: 0.3005 - accuracy: 0.9290 - val_loss: 0.5309 - val_accuracy: 0.7436\n",
            "Epoch 130/200\n",
            "155/155 [==============================] - 0s 425us/step - loss: 0.2726 - accuracy: 0.9613 - val_loss: 0.5229 - val_accuracy: 0.7949\n",
            "Epoch 131/200\n",
            "155/155 [==============================] - 0s 476us/step - loss: 0.3127 - accuracy: 0.9290 - val_loss: 0.5448 - val_accuracy: 0.7436\n",
            "Epoch 132/200\n",
            "155/155 [==============================] - 0s 415us/step - loss: 0.3032 - accuracy: 0.9290 - val_loss: 0.5615 - val_accuracy: 0.7179\n",
            "Epoch 133/200\n",
            "155/155 [==============================] - 0s 545us/step - loss: 0.3026 - accuracy: 0.9226 - val_loss: 0.5846 - val_accuracy: 0.6923\n",
            "Epoch 134/200\n",
            "155/155 [==============================] - 0s 429us/step - loss: 0.3053 - accuracy: 0.9097 - val_loss: 0.6078 - val_accuracy: 0.6923\n",
            "Epoch 135/200\n",
            "155/155 [==============================] - 0s 408us/step - loss: 0.3064 - accuracy: 0.9355 - val_loss: 0.6544 - val_accuracy: 0.6154\n",
            "Epoch 136/200\n",
            "155/155 [==============================] - 0s 476us/step - loss: 0.2984 - accuracy: 0.9097 - val_loss: 0.6339 - val_accuracy: 0.6667\n",
            "Epoch 137/200\n",
            "155/155 [==============================] - 0s 411us/step - loss: 0.2790 - accuracy: 0.9419 - val_loss: 0.6116 - val_accuracy: 0.6923\n",
            "Epoch 138/200\n",
            "155/155 [==============================] - 0s 436us/step - loss: 0.2777 - accuracy: 0.9355 - val_loss: 0.6133 - val_accuracy: 0.6923\n",
            "Epoch 139/200\n",
            "155/155 [==============================] - 0s 401us/step - loss: 0.2868 - accuracy: 0.9355 - val_loss: 0.5811 - val_accuracy: 0.6923\n",
            "Epoch 140/200\n",
            "155/155 [==============================] - 0s 402us/step - loss: 0.3032 - accuracy: 0.9097 - val_loss: 0.5610 - val_accuracy: 0.7436\n",
            "Epoch 141/200\n",
            "155/155 [==============================] - 0s 433us/step - loss: 0.2893 - accuracy: 0.9355 - val_loss: 0.5610 - val_accuracy: 0.7436\n",
            "Epoch 142/200\n",
            "155/155 [==============================] - 0s 418us/step - loss: 0.2751 - accuracy: 0.9419 - val_loss: 0.5659 - val_accuracy: 0.7692\n",
            "Epoch 143/200\n",
            "155/155 [==============================] - 0s 418us/step - loss: 0.2642 - accuracy: 0.9677 - val_loss: 0.5740 - val_accuracy: 0.7436\n",
            "Epoch 144/200\n",
            "155/155 [==============================] - 0s 408us/step - loss: 0.3293 - accuracy: 0.9032 - val_loss: 0.5569 - val_accuracy: 0.7692\n",
            "Epoch 145/200\n",
            "155/155 [==============================] - 0s 423us/step - loss: 0.2938 - accuracy: 0.9161 - val_loss: 0.5681 - val_accuracy: 0.7692\n",
            "Epoch 146/200\n",
            "155/155 [==============================] - 0s 414us/step - loss: 0.2704 - accuracy: 0.9484 - val_loss: 0.5687 - val_accuracy: 0.7179\n",
            "Epoch 147/200\n",
            "155/155 [==============================] - 0s 491us/step - loss: 0.3109 - accuracy: 0.9161 - val_loss: 0.5460 - val_accuracy: 0.7436\n",
            "Epoch 148/200\n",
            "155/155 [==============================] - 0s 565us/step - loss: 0.2489 - accuracy: 0.9548 - val_loss: 0.5457 - val_accuracy: 0.7436\n",
            "Epoch 149/200\n",
            "155/155 [==============================] - 0s 423us/step - loss: 0.2802 - accuracy: 0.9419 - val_loss: 0.5465 - val_accuracy: 0.7436\n",
            "Epoch 150/200\n",
            "155/155 [==============================] - 0s 470us/step - loss: 0.2546 - accuracy: 0.9548 - val_loss: 0.5806 - val_accuracy: 0.7179\n",
            "Epoch 151/200\n",
            "155/155 [==============================] - 0s 443us/step - loss: 0.2753 - accuracy: 0.9226 - val_loss: 0.6072 - val_accuracy: 0.7179\n",
            "Epoch 152/200\n",
            "155/155 [==============================] - 0s 409us/step - loss: 0.2891 - accuracy: 0.9161 - val_loss: 0.6080 - val_accuracy: 0.7179\n",
            "Epoch 153/200\n",
            "155/155 [==============================] - 0s 427us/step - loss: 0.2472 - accuracy: 0.9613 - val_loss: 0.6045 - val_accuracy: 0.7179\n",
            "Epoch 154/200\n",
            "155/155 [==============================] - 0s 503us/step - loss: 0.2525 - accuracy: 0.9484 - val_loss: 0.5982 - val_accuracy: 0.7436\n",
            "Epoch 155/200\n",
            "155/155 [==============================] - 0s 440us/step - loss: 0.2538 - accuracy: 0.9548 - val_loss: 0.5981 - val_accuracy: 0.7179\n",
            "Epoch 156/200\n",
            "155/155 [==============================] - 0s 403us/step - loss: 0.2621 - accuracy: 0.9484 - val_loss: 0.5889 - val_accuracy: 0.7436\n",
            "Epoch 157/200\n",
            "155/155 [==============================] - 0s 436us/step - loss: 0.2515 - accuracy: 0.9548 - val_loss: 0.5944 - val_accuracy: 0.7179\n",
            "Epoch 158/200\n",
            "155/155 [==============================] - 0s 410us/step - loss: 0.2575 - accuracy: 0.9484 - val_loss: 0.6037 - val_accuracy: 0.7179\n",
            "Epoch 159/200\n",
            "155/155 [==============================] - 0s 429us/step - loss: 0.2303 - accuracy: 0.9677 - val_loss: 0.5574 - val_accuracy: 0.7949\n",
            "Epoch 160/200\n",
            "155/155 [==============================] - 0s 425us/step - loss: 0.2541 - accuracy: 0.9484 - val_loss: 0.5710 - val_accuracy: 0.7692\n",
            "Epoch 161/200\n",
            "155/155 [==============================] - 0s 421us/step - loss: 0.3140 - accuracy: 0.9097 - val_loss: 0.5717 - val_accuracy: 0.7692\n",
            "Epoch 162/200\n",
            "155/155 [==============================] - 0s 546us/step - loss: 0.2807 - accuracy: 0.9290 - val_loss: 0.5623 - val_accuracy: 0.7692\n",
            "Epoch 163/200\n",
            "155/155 [==============================] - 0s 419us/step - loss: 0.2804 - accuracy: 0.9226 - val_loss: 0.5760 - val_accuracy: 0.7692\n",
            "Epoch 164/200\n",
            "155/155 [==============================] - 0s 408us/step - loss: 0.2966 - accuracy: 0.9161 - val_loss: 0.5756 - val_accuracy: 0.7692\n",
            "Epoch 165/200\n",
            "155/155 [==============================] - 0s 460us/step - loss: 0.2825 - accuracy: 0.9226 - val_loss: 0.5801 - val_accuracy: 0.7692\n",
            "Epoch 166/200\n",
            "155/155 [==============================] - 0s 414us/step - loss: 0.2725 - accuracy: 0.9419 - val_loss: 0.5786 - val_accuracy: 0.7692\n",
            "Epoch 167/200\n",
            "155/155 [==============================] - 0s 417us/step - loss: 0.2419 - accuracy: 0.9484 - val_loss: 0.5955 - val_accuracy: 0.7179\n",
            "Epoch 168/200\n",
            "155/155 [==============================] - 0s 413us/step - loss: 0.2378 - accuracy: 0.9613 - val_loss: 0.5713 - val_accuracy: 0.7949\n",
            "Epoch 169/200\n",
            "155/155 [==============================] - 0s 475us/step - loss: 0.2455 - accuracy: 0.9484 - val_loss: 0.5637 - val_accuracy: 0.7949\n",
            "Epoch 170/200\n",
            "155/155 [==============================] - 0s 407us/step - loss: 0.2322 - accuracy: 0.9548 - val_loss: 0.5967 - val_accuracy: 0.7436\n",
            "Epoch 171/200\n",
            "155/155 [==============================] - 0s 406us/step - loss: 0.2557 - accuracy: 0.9548 - val_loss: 0.5795 - val_accuracy: 0.7436\n",
            "Epoch 172/200\n",
            "155/155 [==============================] - 0s 431us/step - loss: 0.2369 - accuracy: 0.9548 - val_loss: 0.5709 - val_accuracy: 0.7436\n",
            "Epoch 173/200\n",
            "155/155 [==============================] - 0s 429us/step - loss: 0.2184 - accuracy: 0.9677 - val_loss: 0.6091 - val_accuracy: 0.7436\n",
            "Epoch 174/200\n",
            "155/155 [==============================] - 0s 414us/step - loss: 0.2322 - accuracy: 0.9548 - val_loss: 0.6248 - val_accuracy: 0.7436\n",
            "Epoch 175/200\n",
            "155/155 [==============================] - 0s 423us/step - loss: 0.2279 - accuracy: 0.9613 - val_loss: 0.5941 - val_accuracy: 0.7692\n",
            "Epoch 176/200\n",
            "155/155 [==============================] - 0s 427us/step - loss: 0.2360 - accuracy: 0.9484 - val_loss: 0.5924 - val_accuracy: 0.7692\n",
            "Epoch 177/200\n",
            "155/155 [==============================] - 0s 538us/step - loss: 0.2488 - accuracy: 0.9419 - val_loss: 0.5975 - val_accuracy: 0.7436\n",
            "Epoch 178/200\n",
            "155/155 [==============================] - 0s 410us/step - loss: 0.2144 - accuracy: 0.9742 - val_loss: 0.5996 - val_accuracy: 0.7692\n",
            "Epoch 179/200\n",
            "155/155 [==============================] - 0s 497us/step - loss: 0.2762 - accuracy: 0.9161 - val_loss: 0.6192 - val_accuracy: 0.7436\n",
            "Epoch 180/200\n",
            "155/155 [==============================] - 0s 412us/step - loss: 0.2298 - accuracy: 0.9419 - val_loss: 0.5741 - val_accuracy: 0.7692\n",
            "Epoch 181/200\n",
            "155/155 [==============================] - 0s 428us/step - loss: 0.2817 - accuracy: 0.9161 - val_loss: 0.5706 - val_accuracy: 0.7436\n",
            "Epoch 182/200\n",
            "155/155 [==============================] - 0s 416us/step - loss: 0.2496 - accuracy: 0.9484 - val_loss: 0.5699 - val_accuracy: 0.7179\n",
            "Epoch 183/200\n",
            "155/155 [==============================] - 0s 434us/step - loss: 0.2873 - accuracy: 0.9226 - val_loss: 0.6380 - val_accuracy: 0.7179\n",
            "Epoch 184/200\n",
            "155/155 [==============================] - 0s 418us/step - loss: 0.2355 - accuracy: 0.9484 - val_loss: 0.6213 - val_accuracy: 0.7436\n",
            "Epoch 185/200\n",
            "155/155 [==============================] - 0s 401us/step - loss: 0.2420 - accuracy: 0.9484 - val_loss: 0.6180 - val_accuracy: 0.7436\n",
            "Epoch 186/200\n",
            "155/155 [==============================] - 0s 443us/step - loss: 0.2353 - accuracy: 0.9548 - val_loss: 0.6367 - val_accuracy: 0.7179\n",
            "Epoch 187/200\n",
            "155/155 [==============================] - 0s 541us/step - loss: 0.2696 - accuracy: 0.9161 - val_loss: 0.6137 - val_accuracy: 0.7692\n",
            "Epoch 188/200\n",
            "155/155 [==============================] - 0s 393us/step - loss: 0.2541 - accuracy: 0.9355 - val_loss: 0.6095 - val_accuracy: 0.7692\n",
            "Epoch 189/200\n",
            "155/155 [==============================] - 0s 400us/step - loss: 0.2098 - accuracy: 0.9677 - val_loss: 0.6047 - val_accuracy: 0.7692\n",
            "Epoch 190/200\n",
            "155/155 [==============================] - 0s 427us/step - loss: 0.2809 - accuracy: 0.9290 - val_loss: 0.6126 - val_accuracy: 0.7692\n",
            "Epoch 191/200\n",
            "155/155 [==============================] - 0s 423us/step - loss: 0.2788 - accuracy: 0.9226 - val_loss: 0.6061 - val_accuracy: 0.7692\n",
            "Epoch 192/200\n",
            "155/155 [==============================] - 0s 575us/step - loss: 0.2040 - accuracy: 0.9677 - val_loss: 0.6018 - val_accuracy: 0.7692\n",
            "Epoch 193/200\n",
            "155/155 [==============================] - 0s 461us/step - loss: 0.2137 - accuracy: 0.9613 - val_loss: 0.5783 - val_accuracy: 0.7692\n",
            "Epoch 194/200\n",
            "155/155 [==============================] - 0s 428us/step - loss: 0.2173 - accuracy: 0.9548 - val_loss: 0.5177 - val_accuracy: 0.7949\n",
            "Epoch 195/200\n",
            "155/155 [==============================] - 0s 418us/step - loss: 0.2427 - accuracy: 0.9419 - val_loss: 0.5506 - val_accuracy: 0.7436\n",
            "Epoch 196/200\n",
            "155/155 [==============================] - 0s 423us/step - loss: 0.2123 - accuracy: 0.9613 - val_loss: 0.5171 - val_accuracy: 0.7692\n",
            "Epoch 197/200\n",
            "155/155 [==============================] - 0s 420us/step - loss: 0.2245 - accuracy: 0.9484 - val_loss: 0.5219 - val_accuracy: 0.7692\n",
            "Epoch 198/200\n",
            "155/155 [==============================] - 0s 478us/step - loss: 0.2423 - accuracy: 0.9419 - val_loss: 0.5564 - val_accuracy: 0.7692\n",
            "Epoch 199/200\n",
            "155/155 [==============================] - 0s 421us/step - loss: 0.2354 - accuracy: 0.9355 - val_loss: 0.5757 - val_accuracy: 0.7436\n",
            "Epoch 200/200\n",
            "155/155 [==============================] - 0s 434us/step - loss: 0.2226 - accuracy: 0.9484 - val_loss: 0.5166 - val_accuracy: 0.7949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff461798828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpZFze39bjUt",
        "colab_type": "code",
        "outputId": "469435aa-7794-4775-db16-4a771f1acbd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "import seaborn as sns\n",
        "sns.heatmap(mat,annot=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff53913f390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wvae8UHeJLd",
        "colab_type": "code",
        "outputId": "f2b54dbd-820c-40c2-8aad-d0130021f483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7948717948717948\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87        30\n",
            "           1       0.57      0.44      0.50         9\n",
            "\n",
            "    accuracy                           0.79        39\n",
            "   macro avg       0.71      0.67      0.69        39\n",
            "weighted avg       0.78      0.79      0.79        39\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QwChg8meJH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKrZYDJieJF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI57JLQ8e8W_",
        "colab_type": "text"
      },
      "source": [
        "##KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWqr6QpheJCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn_SQLthdJAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORqCzv7AdNuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9U0Nqr5dahk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBweVGMKfJwz",
        "colab_type": "code",
        "outputId": "9bc607ce-3031-4a9a-fbd9-eb9a3dac496d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "seed=8\n",
        "model = KNeighborsClassifier(n_neighbors = 7)\n",
        "kfold = model_selection.KFold(n_splits=10, random_state = seed)\n",
        "cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zqUbeHafp4Y",
        "colab_type": "code",
        "outputId": "b2db0b7d-6a40-468e-dce8-c32948d9aa78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cv_results.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7887500000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 347
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSY4YldYfsdh",
        "colab_type": "code",
        "outputId": "cde3dd13-88a2-4c4d-b14c-770a35d24b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cv_results.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10773955865883246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2DIZjQvdEzl",
        "colab_type": "code",
        "outputId": "e9ecb273-d4dc-4a72-d0a0-1d7470b84257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print(accuracy_score(y_test, predictions))\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7692307692307693\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.97      0.87        30\n",
            "           1       0.50      0.11      0.18         9\n",
            "\n",
            "    accuracy                           0.77        39\n",
            "   macro avg       0.64      0.54      0.52        39\n",
            "weighted avg       0.72      0.77      0.71        39\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7GrjguidWYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2tlF_6-fMC4",
        "colab_type": "text"
      },
      "source": [
        "##Reccurence time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QMAprFphoiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data=data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mAxtVnNgvdS",
        "colab_type": "code",
        "outputId": "435a72e1-74c7-407a-ae49-5275e1dd2d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "new_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Time</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_std_dev</th>\n",
              "      <th>texture_std_dev</th>\n",
              "      <th>perimeter_std_dev</th>\n",
              "      <th>area_std_dev</th>\n",
              "      <th>smoothness_std_dev</th>\n",
              "      <th>compactness_std_dev</th>\n",
              "      <th>concavity_std_dev</th>\n",
              "      <th>concave_points_std_dev</th>\n",
              "      <th>symmetry_std_dev</th>\n",
              "      <th>fractal_dimension_std_dev</th>\n",
              "      <th>Worst_radius</th>\n",
              "      <th>Worst_texture</th>\n",
              "      <th>Worst_perimeter</th>\n",
              "      <th>Worst_area</th>\n",
              "      <th>Worst_smoothness</th>\n",
              "      <th>Worst_compactness</th>\n",
              "      <th>Worst_concavity</th>\n",
              "      <th>Worst_concave_points</th>\n",
              "      <th>Worst_symmetry</th>\n",
              "      <th>Worst_fractal_dimension</th>\n",
              "      <th>Tumor_Size</th>\n",
              "      <th>Lymph_Node_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N</td>\n",
              "      <td>31</td>\n",
              "      <td>18.02</td>\n",
              "      <td>27.60</td>\n",
              "      <td>117.50</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>0.09489</td>\n",
              "      <td>0.1036</td>\n",
              "      <td>0.1086</td>\n",
              "      <td>0.07055</td>\n",
              "      <td>0.1865</td>\n",
              "      <td>0.06333</td>\n",
              "      <td>0.6249</td>\n",
              "      <td>1.8900</td>\n",
              "      <td>3.972</td>\n",
              "      <td>71.55</td>\n",
              "      <td>0.004433</td>\n",
              "      <td>0.01421</td>\n",
              "      <td>0.03233</td>\n",
              "      <td>0.009854</td>\n",
              "      <td>0.01694</td>\n",
              "      <td>0.003495</td>\n",
              "      <td>21.63</td>\n",
              "      <td>37.08</td>\n",
              "      <td>139.70</td>\n",
              "      <td>1436.0</td>\n",
              "      <td>0.1195</td>\n",
              "      <td>0.1926</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.2677</td>\n",
              "      <td>0.08113</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N</td>\n",
              "      <td>61</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.2776</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N</td>\n",
              "      <td>116</td>\n",
              "      <td>21.37</td>\n",
              "      <td>17.44</td>\n",
              "      <td>137.50</td>\n",
              "      <td>1373.0</td>\n",
              "      <td>0.08836</td>\n",
              "      <td>0.1189</td>\n",
              "      <td>0.1255</td>\n",
              "      <td>0.08180</td>\n",
              "      <td>0.2333</td>\n",
              "      <td>0.06010</td>\n",
              "      <td>0.5854</td>\n",
              "      <td>0.6105</td>\n",
              "      <td>3.928</td>\n",
              "      <td>82.15</td>\n",
              "      <td>0.006167</td>\n",
              "      <td>0.03449</td>\n",
              "      <td>0.03300</td>\n",
              "      <td>0.018050</td>\n",
              "      <td>0.03094</td>\n",
              "      <td>0.005039</td>\n",
              "      <td>24.90</td>\n",
              "      <td>20.98</td>\n",
              "      <td>159.10</td>\n",
              "      <td>1949.0</td>\n",
              "      <td>0.1188</td>\n",
              "      <td>0.3449</td>\n",
              "      <td>0.3414</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4334</td>\n",
              "      <td>0.09067</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N</td>\n",
              "      <td>123</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>R</td>\n",
              "      <td>27</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.1328</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Outcome  Time  ...  Tumor_Size  Lymph_Node_Status\n",
              "0       N    31  ...         5.0                  5\n",
              "1       N    61  ...         3.0                  2\n",
              "2       N   116  ...         2.5                  0\n",
              "3       N   123  ...         2.0                  0\n",
              "4       R    27  ...         3.5                  0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DErFbEuagxvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = new_data.iloc[:, 1].values\n",
        "new_data.drop(['Time'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC5fj8Kointz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencode = LabelEncoder()\n",
        "new_data['Outcome'] = labelencode.fit_transform(new_data['Outcome'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz8o0yOKj0uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(new_data, label, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QwNnuMnkC51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "fit=StandardScaler()\n",
        "X_train =fit.fit_transform(X_train)\n",
        "X_test = fit.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY0V7X2wkIwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-8pWpAzfRYa",
        "colab_type": "code",
        "outputId": "e8e6cec9-1c7d-4f2c-bc07-ad8e79d6001e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor  \n",
        "regressor = DecisionTreeRegressor(random_state = 0)  \n",
        "regressor.fit(X_train, y_train) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw-OsyRqgQRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_dct = regressor.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I-dMAwZkZBg",
        "colab_type": "code",
        "outputId": "92175076-a6bc-43cd-c327-8b14b5aade89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_test, predictions_dct)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1690.871794871795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czdEQmd8l_k3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JMg_MpDlLqe",
        "colab_type": "code",
        "outputId": "133e28b5-d171-4509-f084-4f464367fe49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "param_grid = {\"criterion\": [\"mse\", \"mae\"],\n",
        "              \"min_samples_split\": [2,3,4,6,8,10],\n",
        "              \"max_depth\": [2,4, 6, 8,10],\n",
        "              \"min_samples_leaf\": [2,5,10,20],\n",
        "              \"max_leaf_nodes\": [2,3,5,10, 20, 100],\n",
        "              }\n",
        "\n",
        "## Comment in order to publish in kaggle.\n",
        "\n",
        "grid_cv_dtm = GridSearchCV(regressor, param_grid, cv=10)\n",
        "\n",
        "grid_cv_dtm.fit(X_train, y_train) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
              "                                             max_depth=None, max_features=None,\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             presort='deprecated',\n",
              "                                             random_state=0, splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': ['mse', 'mae'],\n",
              "                         'max_depth': [2, 4, 6, 8, 10],\n",
              "                         'max_leaf_nodes': [2, 3, 5, 10, 20, 100],\n",
              "                         'min_samples_leaf': [2, 5, 10, 20],\n",
              "                         'min_samples_split': [2, 3, 4, 6, 8, 10]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Sdaxhpmkuw",
        "colab_type": "code",
        "outputId": "6dc46be4-a3a5-470f-8b57-6db5129b2426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"R-Squared::{}\".format(grid_cv_dtm.best_score_))\n",
        "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtm.best_params_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R-Squared::0.04103943051525388\n",
            "Best Hyperparameters::\n",
            "{'criterion': 'mae', 'max_depth': 2, 'max_leaf_nodes': 2, 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUpBY6fZmGXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_dct1=grid_cv_dtm.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clKL8s6gmUGy",
        "colab_type": "code",
        "outputId": "4d69a3cf-8cfe-4542-8d94-64f3aa904aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_test, predictions_dct1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1332.320512820513"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY0OFOIFnHJW",
        "colab_type": "text"
      },
      "source": [
        "##XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lNrI01KplRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import  xgboost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzxXBp_knNnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = xgboost.XGBRegressor(colsample_bytree=0.4, gamma=0,  learning_rate=0.07, max_depth=3,min_child_weight=1.5,n_estimators=10000,  reg_alpha=0.75,  reg_lambda=0.45,subsample=0.6, seed=42) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjHNrJpDpoAh",
        "colab_type": "code",
        "outputId": "a75571d7-d001-4f55-dc84-ea7ffabd5d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[21:18:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=0.4, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.07, max_delta_step=0,\n",
              "             max_depth=3, min_child_weight=1.5, missing=None,\n",
              "             n_estimators=10000, n_jobs=1, nthread=None, objective='reg:linear',\n",
              "             random_state=0, reg_alpha=0.75, reg_lambda=0.45,\n",
              "             scale_pos_weight=1, seed=42, silent=None, subsample=0.6,\n",
              "             verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU71O3slpsuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_xgb=model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27ZciqJYp0EC",
        "colab_type": "code",
        "outputId": "83e791d4-8ba4-49b9-e391-79d3c7c790e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean_squared_error(y_test, predict_xgb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1167.3218564060699"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqkHmBWip5Fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb1 = xgboost.XGBRegressor()\n",
        "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
        "              'objective':['reg:linear'],\n",
        "              'learning_rate': [0.001,0.01,0.03, 0.05, .07], #so called `eta` value\n",
        "              'max_depth': [5, 6, 7],\n",
        "              'min_child_weight': [2,4,6],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.7],\n",
        "              'colsample_bytree': [0.7],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "xgb_grid = GridSearchCV(xgb1, parameters, cv = 10, n_jobs = 5,  verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k5DsmHqqPww",
        "colab_type": "code",
        "outputId": "c2e22756-0582-4dbb-b3d3-7c2cfd0872cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "xgb_grid.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 45 candidates, totalling 450 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
            "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   23.8s\n",
            "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=5)]: Done 440 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=5)]: Done 450 out of 450 | elapsed:  4.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
              "                                    colsample_bylevel=1, colsample_bynode=1,\n",
              "                                    colsample_bytree=1, gamma=0,\n",
              "                                    importance_type='gain', learning_rate=0.1,\n",
              "                                    max_delta_step=0, max_depth=3,\n",
              "                                    min_child_weight=1, missing=None,\n",
              "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
              "                                    objective='reg:linear', random_state=0,\n",
              "                                    reg_alpha=0, reg...\n",
              "                                    subsample=1, verbosity=1),\n",
              "             iid='deprecated', n_jobs=5,\n",
              "             param_grid={'colsample_bytree': [0.7],\n",
              "                         'learning_rate': [0.001, 0.01, 0.03, 0.05, 0.07],\n",
              "                         'max_depth': [5, 6, 7], 'min_child_weight': [2, 4, 6],\n",
              "                         'n_estimators': [500], 'nthread': [4],\n",
              "                         'objective': ['reg:linear'], 'silent': [1],\n",
              "                         'subsample': [0.7]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLIWZHWGq22V",
        "colab_type": "code",
        "outputId": "05deb1f3-df6a-4b26-eab7-6470e3e78cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(xgb_grid.best_score_)\n",
        "print(xgb_grid.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.05916890428772834\n",
            "{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 6, 'n_estimators': 500, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRkMdZQoqiWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_xgb1=xgb_grid.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHPKywWYqvnw",
        "colab_type": "code",
        "outputId": "f97b171a-48c2-48d4-9b59-5427c8714343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean_squared_error(y_test, predict_xgb1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "880.8159769528589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWN_54gtq0b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}